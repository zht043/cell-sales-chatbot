{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a79a8a3c-7b8d-42c7-a207-058419200afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "from utils.prompter import Prompter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3a878a-3123-4fcb-ac37-a7cb6cb141d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = \"cuda\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "961f083d-d71c-46b7-9f10-152c4d6630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_8bit = False\n",
    "base_model = 'decapoda-research/llama-7b-hf'\n",
    "lora_weights = 'tloen/alpaca-lora-7b'\n",
    "#lora_weights = \"/workspace/cell-sales-chatbot/model-weights/alpaca-phone\"\n",
    "# The prompt template to use, will default to alpaca.\n",
    "prompt_template = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edd3e3-75f6-4baa-8631-fb842b2f479e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dae8d1-ca4f-4a71-9a52-3c6e67950ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66737b5f-48fc-45c4-be1d-48b8aabacd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbf707288184e9c938b8606adbceca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "if device == \"cuda\":\n",
    "    alp_model = LlamaForCausalLM.from_pretrained(base_model, load_in_8bit=load_8bit,\n",
    "                    torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9089792b-596b-42b1-a09e-7b935b50df2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40004ff-9b8c-47bf-9d7e-8068c6bbb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if can't find xxx.json error occurred, check the lora_weights variable, trying using full system path\n",
    "\n",
    "if device == \"cuda\":\n",
    "    alp_model = PeftModel.from_pretrained(alp_model, lora_weights, torch_dtype=torch.float16)\n",
    "\n",
    "# unwind broken decapoda-research config\n",
    "alp_model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "alp_model.config.bos_token_id = 1\n",
    "alp_model.config.eos_token_id = 2\n",
    "\n",
    "if not load_8bit:\n",
    "    alp_model.half()  # seems to fix bugs for some users.\n",
    "\n",
    "alp_model.eval()\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    alp_model = torch.compile(alp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796f0c7-ef80-4659-b93d-153b209ba771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9784b97-d743-4100-bdb0-282d57d4080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd6278-95c0-47af-a32d-4710dd658513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ffd8d-cae1-43d1-881d-44409c7b5f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae62fef-75ee-49ca-9ea4-4f6611ee0e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b64262db-57f0-409b-8e3b-58c2932daa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompter = Prompter(prompt_template)\n",
    "\n",
    "def alpaca_inference(input_text, instructions, \n",
    "    temperature = 0.3, top_p = 0.75, top_k = 40, num_beams = 1, \n",
    "    max_new_tokens = 256, **kwargs):\n",
    "    \n",
    "    input_prompt = prompter.generate_prompt(instructions, input_text)\n",
    "    generation_config = GenerationConfig(temperature=temperature, top_p=top_p,\n",
    "        top_k=top_k, num_beams=num_beams, **kwargs)\n",
    "    \n",
    "    inputs = tokenizer(input_prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        generation_output = alp_model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    return prompter.get_response(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4a7e1-05b1-4b9a-9997-3016ce194aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8acb4b4-87a5-400d-a229-7cf6a991b744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fecf4a09-aa1e-4b68-be4d-7823ed2f5356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Instruction:\n",
      " Hi, how are you?\n",
      ">>>>> Input:\n",
      " Hi, how are you?\n",
      "<<<<< Output:\n",
      " Hello, I am doing well. How are you?\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "\n",
      "### Input:\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\n",
    "\n",
    "input_text = \"Hi, how are you?\"\n",
    "\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "print(\">>>>> Instruction:\\n\", input_text)\n",
    "print(\">>>>> Input:\\n\", input_text)\n",
    "print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677159b-d01b-476d-910e-02e733a803da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e614af-c850-414d-8f95-34c73d3d30a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121bbfd4-9d16-4d53-930e-e54b64fa877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9a47d-b979-4e80-93ce-00509a91e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aabb610-e92d-44fc-925d-56a4bf5310d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Instruction:\n",
      " Extract phone model names\n",
      "output only the comma-separated model names\n",
      ">>>>> Input:\n",
      " Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n",
      "<<<<< Output:\n",
      " Apple iPhone SE: 14 hours\n",
      "Xiaomi Redmi Note 9 Pro: 5 hours\n",
      "Huawei P30 Pro: 2 days\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Extract phone model names\\n\\\n",
    "output only the comma-separated model names\"\n",
    "\n",
    "input_text = query1\n",
    "\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "print(\">>>>> Instruction:\\n\", instruction)\n",
    "print(\">>>>> Input:\\n\", input_text)\n",
    "print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65a24d-8c85-4b6f-952e-f3a2bac34dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3297a20-06f4-4a79-a336-a0d66dd0ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Instruction:\n",
      " How many phones model names are there in the input?\n",
      "\n",
      ">>>>> Input:\n",
      " Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n",
      "<<<<< Output:\n",
      " Apple iPhone SE: 1440 mAh\n",
      "Xiaomi Redmi Note 9 Pro: 4000 mAh\n",
      "Huawei P30 Pro: 4200 mAh\n"
     ]
    }
   ],
   "source": [
    "instruction = '''How many phones model names are there in the input?\n",
    "'''\n",
    "\n",
    "input_text = query1\n",
    "\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "print(\">>>>> Instruction:\\n\", instruction)\n",
    "print(\">>>>> Input:\\n\", input_text)\n",
    "print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf596f-fb7d-4baf-942c-8d351e75bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9246c3f4-89e4-43c5-8726-c19e21e75a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Load stuff\n",
    "with open(\"phone_dataset.pkl\", \"rb\") as f:\n",
    "    pdb = pickle.load(f)\n",
    "    \n",
    "phonedb_data, name_map = pdb\n",
    "name_list = list(name_map.keys())\n",
    "\n",
    "def query_specs_list(short_name, debug=False, replace_new_line = True):\n",
    "    spec_list = []\n",
    "    for ln in name_map[short_name]:\n",
    "        if debug:\n",
    "            print(ln)\n",
    "        if replace_new_line:\n",
    "            spec = phonedb_data[ln][0].replace(\"\\\\n\", \"\\n\")\n",
    "        else:\n",
    "            spec = phonedb_data[ln][0]\n",
    "        spec_list.append(spec)\n",
    "    return spec_list\n",
    "\n",
    "def query_key_text_list(short_name, debug=False, replace_new_line = True):\n",
    "    key_text = []\n",
    "    for ln in name_map[short_name]:\n",
    "        if debug:\n",
    "            print(ln)\n",
    "        if replace_new_line:\n",
    "            spec = phonedb_data[ln][0].replace(\"\\\\n\", \"\\n\")\n",
    "        else:\n",
    "            spec = phonedb_data[ln][0]\n",
    "        key_text.append([ln, spec])\n",
    "    return key_text\n",
    "\n",
    "def fuzzy_score(sentence, word):\n",
    "    return fuzz.partial_ratio(word.lower(), sentence.lower())\n",
    "\n",
    "def fuzzy_scores(sentence, word_list):\n",
    "    result = []\n",
    "    for word in word_list:\n",
    "        score = fuzz.partial_ratio(word.lower(), sentence.lower())\n",
    "        result.append([word, score])\n",
    "    return result    \n",
    "def topk_lables(fuzzy_score_list, k = 5):\n",
    "    fs_sort = sorted(fuzzy_score_list, key=lambda x: x[1], reverse=True)\n",
    "    lbs = []\n",
    "    if k < len(fs_sort):\n",
    "        for i in range(k):\n",
    "             lbs.append(fs_sort[i][0])\n",
    "    else:\n",
    "        for i in range(len(fs_sort)):\n",
    "             lbs.append(fs_sort[i][0])\n",
    "    return lbs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cac6a9fd-0681-4edb-8823-8c03b013409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Galaxy S21 Ultra\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "\n",
    "def efficient_bart_cls_inference(text, long_label_list):\n",
    "    narrowed_labels = topk_lables(fuzzy_scores(text, long_label_list)) #narrowed down to short name list\n",
    "    result = classifier(text, narrowed_labels, multiclass=True)\n",
    "    return result\n",
    "\n",
    "#Example:\n",
    "result = efficient_bart_cls_inference(\"Can you give me the weight for the Samsung Galaxy S21 Ultra?\", \n",
    "                                    name_list)\n",
    "pred_model_name = result[\"labels\"][0]\n",
    "print(pred_model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe07db-a34c-46e1-883c-178b92b671ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0d7e2-d4ae-41a5-85eb-2fe988982c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9258a-8f31-4abe-bd30-b0af63e19f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8881893e-2c24-436b-a0e1-df7a609c9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_query_mix_models_inference(sentence, model_name_list, print_process = False):\n",
    "    ### Step 1: Alpaca extract name tokens\n",
    "    instruction = \"Ignore the input. Extract all phone model names from the input sentence. \\\n",
    "Append and prepend '%%%' symbols to each phone model name.\" \n",
    "\n",
    "    input_text = sentence\n",
    "    \n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"Step 1: Alpaca extract name tokens\")\n",
    "        print(\"\\n>>>>> Instruction:\\n\", instruction)\n",
    "        print(\"\\n>>>>> Input:\\n\", input_text)\n",
    "        print(\"\\nGenerating ......\")\n",
    "    \n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output = alpaca_inference(input_text, instruction, max_new_tokens = 128)\n",
    "    \n",
    "    output = output.split('###')[0].strip()\n",
    "    output = output.strip()\n",
    "    if print_process:\n",
    "        print(\"\\n<<<<< Output:\\n\", output)\n",
    "    \n",
    "    if print_process:\n",
    "        print(\"\\n------------------------------------------------\")\n",
    "        print(\"Using regex to tokenize:\")\n",
    "    matches = re.findall(r'%%([\\w\\s]+?)%%', output.replace(\"\\n\", \"\"))\n",
    "    \n",
    "    matches = list(set(matches))\n",
    "    if print_process:\n",
    "        print(matches)\n",
    "    \n",
    "    ### Step 2: iteratively call Bart classifier to get name keys for dict query\n",
    "    ###         using the alpaca output as its input\n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"\\nStep 2: Zero-shot BART classifier extract name keys\\n\")\n",
    "    results = set()\n",
    "    \n",
    "    for token in matches:\n",
    "        #Using fuzzy similarity scores to get top K candidate model names\n",
    "        narrowed_labels = topk_lables(fuzzy_scores(token, model_name_list), k = 5) \n",
    "        \n",
    "        cls_result = classifier(token, narrowed_labels, multiclass=True)\n",
    "        pred = cls_result[\"labels\"][0]\n",
    "        results.add(pred)\n",
    "        \n",
    "        if print_process:\n",
    "            print(\"Extracted Model Name: \", pred)\n",
    "    \n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\\n\\n\") \n",
    "            \n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1582598-3b52-4c62-8dda-1dde4af24b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " How does the Face ID feature on Apple iphone14 pro compare to the fingerprint sensor on the Huawei Mate40 Pro and Samsung Galaxy S10?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%Apple iPhone14 Pro%%,%%Face ID%%,%%%%Compare%%,%%%%Fingerprint%%,%%%%Sensor%%,%%%%S10%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Fingerprint', 'Apple iPhone14 Pro', 'Face ID', 'S10', 'Sensor', 'Compare']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  Xiaomi Redmi Note 11T Pro\n",
      "Extracted Model Name:  iPhone 14 Pro\n",
      "Extracted Model Name:  Samsung Galaxy A9 Star Lite\n",
      "Extracted Model Name:  Samsung Galaxy S10+\n",
      "Extracted Model Name:  Xiaomi Mi 6 Mercury Silver\n",
      "Extracted Model Name:  Xiaomi Redmi 12C\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"How does the Face ID feature on Apple iphone14 pro \\\n",
    "compare to the fingerprint sensor on the Huawei Mate40 Pro and Samsung Galaxy S10?\"\n",
    "\n",
    "\n",
    "names = name_query_mix_models_inference(query2, name_list, print_process=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af60d78-e382-41b3-bcd1-c14081399798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654aed79-1963-4414-8cf6-aa09900c3958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " What is the camera resolution for the Huawei P40?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%Huawei P40%%Camera Resolution: 12MP+24MP+8MP+1080p@30fps+120fps@1080p+720p@30fps+2160p@30fps\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Huawei P40']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  Huawei P40\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query5 = \"What is the camera resolution for the Huawei P40?\"\n",
    "\n",
    "\n",
    "names = name_query_mix_models_inference(query5, name_list, print_process=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5d4a6-e37c-4227-898f-93bc13320d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b40010a0-964c-453f-abcd-7287d5b3941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " How do the camera capabilities of the Apple iPhone 12, Samsung Galaxy S21, and Xiaomi Mi 11 compare?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%Apple iPhone 12%%, %%Samsung Galaxy S21%%, %%Xiaomi Mi 11%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Xiaomi Mi 11', 'Samsung Galaxy S21', 'Apple iPhone 12']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  Xiaomi Mi 11\n",
      "Extracted Model Name:  Samsung Galaxy S21\n",
      "Extracted Model Name:  iPhone 12\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query6 = \"How do the camera capabilities of the Apple iPhone 12, Samsung Galaxy S21, and Xiaomi Mi 11 compare?\"\n",
    "\n",
    "names = name_query_mix_models_inference(query6, name_list, print_process=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514d1a7-57f6-4a6e-bd16-fd17f1ca724f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b554086-c828-4809-8d0c-f1055863462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " Can you list the battery life for the Apple iPhone 13, Xiaomi Redmi Note 9 Pro,and Huawei P30 Pro?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%Apple iPhone 13%%\n",
      "%%Xiaomi Redmi Note 9 Pro%%\n",
      "%%Huawei P30 Pro%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Apple iPhone 13', 'Xiaomi Redmi Note 9 Pro', 'Huawei P30 Pro']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  iPhone 13\n",
      "Extracted Model Name:  Xiaomi Redmi Note 9 Pro\n",
      "Extracted Model Name:  Huawei P30 Pro\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Querying local DataBase ......\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Xiaomi Redmi Note 9 Pro  related texts:\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Xiaomi \n",
      " Model: Redmi Note 9 Pro 5G Premium Edition Dual SIM TD-LTE CN 256GB M2007J17C \n",
      " Brie \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Xiaomi \n",
      " Model: Redmi Note 9 Pro 5G Premium Edition Dual SIM TD-LTE CN 128GB M2007J17C \n",
      " Brie \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Xiaomi \n",
      " Model: Redmi Note 9 Pro 5G Standard Edition Dual SIM TD-LTE CN 128GB M2007J17C \n",
      " Bri \n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "iPhone 13  related texts:\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 mini 5G A2629 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: Ceramic Shield, \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 mini 5G A2629 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: iOS 15 enhances \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 mini 5G A2629 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: iPhone 13 mini  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 5G A2634 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: The most affordable  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 5G A2634 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: Top Chinese full net \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 5G A2634 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: Upper mid-range iPho \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 1TB \n",
      " Brief Info: Top variant of hig \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: Super Retina XDR \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: The most afforda \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: iOS 15 enhances  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 1TB \n",
      " Brief Info: Top variant of \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: The most aff \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: All-new Supe \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: The wide-ang \n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Huawei P30 Pro  related texts:\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN VOG-AL00 128GB \n",
      " Brief Info: Chine \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN VOG-AL00 256GB \n",
      " Brief Info: P30 P \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN VOG-TL00 128GB \n",
      " Brief Info: China \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN 512GB VOG-AL00 / VOG-AL10 \n",
      " Brief  \n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Example to query phonedb database using mix models\n",
    "\n",
    "query3 = \"Can you list the battery life for the Apple iPhone 13, Xiaomi Redmi Note 9 Pro,\\\n",
    "and Huawei P30 Pro?\"\n",
    "\n",
    "\n",
    "key_names = name_query_mix_models_inference(query3, name_list, print_process=True)\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Querying local DataBase ......\")\n",
    "for n in key_names:\n",
    "    specs_texts = query_specs_list(n)\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(n, \" related texts:\")\n",
    "    for text in specs_texts:\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print(text[0:100], \"\\n\") #only print the first 100 chars of a text\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd87420-4e0f-49bd-bf8d-9de85c92b3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df096253-0075-4367-bf3f-320a4a6c60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def string_line_filter(string, filter_keywords, filter_out=True):\n",
    "    lines = string.splitlines()\n",
    "    filtered_lines = []\n",
    "    for line in lines:\n",
    "        append = True if filter_out else False\n",
    "        for keyword in filter_keywords:\n",
    "            if keyword in line:\n",
    "                append = False if filter_out else True\n",
    "        if append:\n",
    "            filtered_lines.append(line)\n",
    "    new_string = \"\\n\".join(filtered_lines)\n",
    "    \n",
    "    return new_string\n",
    "\n",
    "def extract_table_keys(text):\n",
    "    lines = text.splitlines()\n",
    "    keys = []\n",
    "    for line in lines:\n",
    "        key = line.split(\":\", maxsplit=1)[0]        \n",
    "        keys.append(key.strip())\n",
    "    return keys\n",
    "\n",
    "def table_findall(text, keyword):\n",
    "    pattern = r'.*\\b(' + \"Camera\" + r')\\b.*'\n",
    "    matches = [line.strip() for line in text.split('\\n') if re.match(pattern, line)]\n",
    "    return matches\n",
    "\n",
    "\n",
    "sentsim_transformer = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def sentence_similarity(sentsim_model, text1, text2):\n",
    "    embedding_1= sentsim_model.encode(text1, convert_to_tensor=True)\n",
    "    embedding_2 = sentsim_model.encode(text2, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(embedding_1, embedding_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c859ae-0826-4e38-b6fc-60314b6d94c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xxx = query_specs_list(\"iPhone 12\")[0]\n",
    "\n",
    "\n",
    "# keys = extract_table_keys(xxx)\n",
    "\n",
    "# len(keys)\n",
    "\n",
    "# table_findall(xxx, \"camera\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef55883-c2e8-489f-9ef3-a57ca7037ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1ba5021-b888-4185-a2a8-f4374ceb0ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "\n",
    "def qa_inference(question, context, model_name=\"deepset/roberta-base-squad2\"):\n",
    "    nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
    "    QA_input = {\n",
    "        'question': question,\n",
    "        'context': context    \n",
    "    }\n",
    "    return nlp(QA_input)\n",
    "\n",
    "def relevant_table_text(question, text, topk = 3):\n",
    "    lines = text.splitlines()\n",
    "    relevant_text = \"\"\n",
    "    scores = []\n",
    "    for line in tqdm(lines):\n",
    "        score = sentence_similarity(sentsim_transformer, question, line).item()\n",
    "        scores.append([line, score])\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i in range(topk):\n",
    "        relevant_text += scores[i][0] + \"\\n\"\n",
    "    return relevant_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01b50c66-4bd3-44e5-b88c-3506d1fdf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 92.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Brief Info: Compact iPhone model sharing most of its high-end features with the larger siblings in the 12 / 12 Pro model range, like A14 Bionic SoC, XDR AMOLED display, 12 MP wide and 12 MP ultra-wide rear cameras. Top 256 GB variant mainland for China, Hong Kong, Ma \n",
      " Aux. Camera Extra Functions: HDR photo, Slow motion video, Burst mode, Touch focus, Panorama Photo, Face detection, Face tagging, Smile detection \n",
      " Number of effective pixels: 12.2 MP camera \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rel = relevant_table_text(\"How do the camera capabilities of the Apple iPhone 12,\\\n",
    "Samsung Galaxy S21, and Xiaomi Mi 11 compare?\"\n",
    ", query_specs_list(\"iPhone 12\")[0])\n",
    "\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "585a88ab-b72d-4201-aab1-8d32438fe33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"How do the camera capabilities of the Apple iPhone 12, Samsung Galaxy S21, and Xiaomi Mi 11 compare?\"\n",
    "\n",
    "# key_names = name_query_mix_models_inference(question, name_list, print_process=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\n------------------------------------------------\")\n",
    "# print(\"Querying local DataBase ......\")\n",
    "# for n in key_names:\n",
    "#     specs_texts = query_specs_list(n)\n",
    "#     print(\"++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "#     print(n, \" related texts:\")\n",
    "#     for text in specs_texts:\n",
    "#         print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "#         relevant_text = relevant_table_text(question, text, topk=5)\n",
    "        \n",
    "#         print(qa_inference(question, context = relevant_text))\n",
    "# print(\"------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c762d1-8fa3-4f20-8db0-d228dfa0d3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d54aa-ace2-4393-b9ec-4a0e6e7df43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497499f9-b8bd-4e7a-8ae8-998fb8774193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32cae5d6-b909-474f-a500-ed54e3abb882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " How do the camera capabilities of the Apple iPhone 12, Samsung Galaxy S21, and Xiaomi Mi 11 compare?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%Apple iPhone 12%%, %%Samsung Galaxy S21%%, %%Xiaomi Mi 11%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Xiaomi Mi 11', 'Samsung Galaxy S21', 'Apple iPhone 12']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  Xiaomi Mi 11\n",
      "Extracted Model Name:  Samsung Galaxy S21\n",
      "Extracted Model Name:  iPhone 12\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Querying local DataBase ......\n",
      "Model Name Family:  iPhone 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [00:01<00:00, 89.45it/s]\n",
      "100%|██████████| 159/159 [00:01<00:00, 95.08it/s]\n",
      "100%|██████████| 158/158 [00:01<00:00, 94.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name Family:  Xiaomi Mi 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:01<00:00, 89.10it/s]\n",
      "100%|██████████| 145/145 [00:01<00:00, 95.14it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 93.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name Family:  Samsung Galaxy S21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:01<00:00, 92.20it/s]\n",
      "100%|██████████| 166/166 [00:01<00:00, 96.02it/s]\n",
      "100%|██████████| 173/173 [00:01<00:00, 95.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      ".................................................\n",
      "The iPhone 12 Mini 5G A2400 Dual SIM TD-LTE CN 64GB / A2401 is the most affordable 64 GB variant of iPhone 12 Mini for mainland China, Hong Kong, Macao featuring Super Retina XDR AMOLED display protected by Ceramic Shield, 12 + 12 MP wide-angle rear cameras and 12 MP TrueDepth front camera. It has HDR photo, Slow motion video, Burst mode, Touch focus, Panorama Photo, Face detection, Face tagging, Smile detection and 12.2 MP camera. The iPhone 12 5G A2404 Dual SIM TD-LTE CN 64GB / A2405 is the most affordable 64 GB variant of iPhone 12 for mainland China, Hong Kong and Macao featuring Super Retina XDR AMOLED display protected by Ceramic Shield, 12 + 12 MP wide-angle rear cameras and 12 MP TrueDepth front camera. It has HDR photo\n",
      "\n",
      "Xiaomi Mi 11 Youth 5G Premium Edition Dual SIM TD-LTE CN 256GB M2101K9C is a Chinese variant of Mi11 Lite 5G smartphone with 256 GB UFS 2.2 ROM, 8 GiB LP-DDR4X RAM. Xiaomi Mi 11 Youth 5G Premium Edition Dual SIM TD-LTE CN 128GB M2101K9C is a Chinese variant of Mi11 Lite 5G smartphone with 128 GB UFS 2.2 ROM, 8 GiB LP-DDR4X RAM. Xiaomi Mi 11 Pro 5G Premium Edition Dual SIM TD-LTE CN 256GB M2102K1AC is a Chinese variant of Mi11 Pro 5G smartphone with 256 GB UFS 2.2 ROM, 8 GiB LP-DDR4X RAM.\n",
      "\n",
      "The Samsung SM-G9960 Galaxy S21+ 5G Dual SIM TD-LTE CN HK 256GB is a powerful cellphone with a 12.2 MP camera, Samsung ISOCELL Plus S5K2LD camera module, and an adaptive display with support for 10 Hz to 120 Hz at Quad HD+ quality. It also has dual nano-SIM slots and 128 GB of storage. The Samsung SM-G9960 Galaxy S21+ 5G Dual SIM TD-LTE CN HK 128GB is a powerful cellphone with a 12.2 MP camera, Samsung ISOCELL Plus S5K2LD camera module, and an adaptive display with support for 10 Hz to 120 Hz at Quad HD+ quality. It also has dual nano-SIM slots and 128 GB of storage. The Samsung SM-G9980 Galaxy S21 Ultra 5G Dual SIM TD-LTE C\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = \"How do the camera capabilities of the Apple iPhone 12, Samsung Galaxy S21, and Xiaomi Mi 11 compare?\"\n",
    "\n",
    "key_names = name_query_mix_models_inference(question, name_list, print_process=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Querying local DataBase ......\")\n",
    "\n",
    "context_text = \"\"\n",
    "for n in key_names:\n",
    "    keys_texts = query_key_text_list(n)\n",
    "    relevant_texts = []\n",
    "    \n",
    "    print(\"Model Name Family: \", n)\n",
    "    \n",
    "    # too many texts, crashed the alpaca model, added a simple filter\n",
    "    topk = 3\n",
    "    keys_list = []\n",
    "    texts_list = []\n",
    "    for key, text in keys_texts:\n",
    "        keys_list.append(key)\n",
    "        texts_list.append(text)\n",
    "    cls_res = efficient_bart_cls_inference(question, keys_list)\n",
    "    keys_texts_ranked = []\n",
    "    ranked_keys = cls_res[\"labels\"][0 : topk]\n",
    "    for i in range(len(keys_list)):\n",
    "        if keys_list[i] in ranked_keys:\n",
    "            keys_texts_ranked.append([keys_list[i], texts_list[i]])\n",
    "    \n",
    "    \n",
    "    for ln, text in keys_texts_ranked:\n",
    "        relevant_text = \"Model full name is '\" + ln + \"':\\n\"\n",
    "        relevant_text += relevant_table_text(question, text, topk=3)\n",
    "        relevant_text += \"\\n\"\n",
    "        #print(relevant_text)\n",
    "        relevant_texts.append(relevant_text)\n",
    "    sum_rele_text = ' '.join(relevant_texts)\n",
    "    #print(sum_rele_text)\n",
    "    \n",
    "    # summarize\n",
    "    instruction = '''Summarize the input passage which contains info about\\\n",
    "different specific models of a cellphone family\n",
    "'''\n",
    "\n",
    "    input_text = sum_rele_text\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output = alpaca_inference(input_text, instruction)\n",
    "    \n",
    "    output = output.split('###')[0].strip()\n",
    "    output = output.strip()\n",
    "    context_text += output + \"\\n\\n\" \n",
    "    \n",
    "        \n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "print(\".................................................\")\n",
    "print(context_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529e81f-ca75-437d-8241-b95dac5e5a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88b554-3a6f-497c-b96f-cc5452e84b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc75f7bd-4ac9-42eb-8097-1f0852069420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15673d1c-9225-4444-b89d-b47f600039fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e3a3a-b7aa-4f70-afe0-ccd3a8ce307a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfae9bf-df5f-4809-b12f-1a725b5cd603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8604a-a47a-45d4-918e-7cffede657a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348009dd-4e15-485c-a6a6-7dff0b6e90ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62cdc00-3901-4050-929f-04e03790a1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ff453-4cc3-4ab6-98d1-9d54a3741719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac591158-db28-4b86-af7f-ce2bfc26bc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1d244-9ffe-4f2f-aa04-4abf294640ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e9cfc-bc10-4581-8f25-283ef27a9256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324b7836-9dc2-4ee5-8d42-29102435c169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb2d0f78-1d54-4469-9caf-a4974208e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instruction = '''Summarize the input passage which contains info about\\\n",
    "# different specific models of a cellphone family\n",
    "# '''\n",
    "\n",
    "# input_text = ltext\n",
    "\n",
    "# with torch.autocast(\"cuda\"):\n",
    "#     output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "# print(\">>>>> Instruction:\\n\", instruction)\n",
    "# print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e41919-5f6c-46e7-8ed6-18afd7ae4048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae40e90d-3c71-4307-9720-4714d5c0ff8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6208f0c-0246-4781-b475-dd9ca404df04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef14e02-bb4d-46d5-bda1-ad249b99cab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da7a31-2b0c-4d10-93bd-4a5c6a6f4bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630a4f6-7ede-4e19-9e15-d42debea7fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05c743c-c273-48eb-a556-0d0711117dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd97a808-3d2a-465b-99f0-6d49dffa7d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " How do the camera capabilities of the Apple iPhone 12,Samsung Galaxy S21, and Xiaomi Mi 11 compare?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%Apple iPhone 12%%,%%Samsung Galaxy S21%%,%%Xiaomi Mi 11%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Xiaomi Mi 11', 'Samsung Galaxy S21', 'Apple iPhone 12']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  Xiaomi Mi 11\n",
      "Extracted Model Name:  Samsung Galaxy S21\n",
      "Extracted Model Name:  iPhone 12\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Querying local DataBase ......\n",
      "Model Name Family:  iPhone 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [00:01<00:00, 87.91it/s]\n",
      "100%|██████████| 159/159 [00:01<00:00, 96.47it/s]\n",
      "100%|██████████| 158/158 [00:01<00:00, 96.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name Family:  Xiaomi Mi 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:01<00:00, 91.49it/s]\n",
      "100%|██████████| 145/145 [00:01<00:00, 93.96it/s]\n",
      "100%|██████████| 150/150 [00:01<00:00, 94.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name Family:  Samsung Galaxy S21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 166/166 [00:01<00:00, 89.09it/s]\n",
      "100%|██████████| 166/166 [00:01<00:00, 94.32it/s]\n",
      "100%|██████████| 173/173 [00:01<00:00, 94.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "The iPhone 12 Mini 5G A2400 Dual SIM TD-LTE CN 128GB / A2401 is the most affordable variant of the iPhone 12 Mini for mainland China, Hong Kong and Macao. It features a Super Retina XDR AMOLED display protected by Ceramic Shield, 12 + 12 MP wide-angle rear cameras and 12 MP TrueDepth front camera. It also has HDR photo, Slow motion video, Burst mode, Touch focus, Panorama Photo, Face detection, Face tagging, Smile detection and 12.2 MP camera. The iPhone 12 Mini 5G A2400 Dual SIM TD-LTE CN 64GB / A2401 is the most affordable variant of the iPhone 12 Mini for mainland China, Hong Kong and Macao. It features a Super Retina XDR AMOLED display protected by Ceramic Shield, 12 + 12 MP wide-angle rear cameras and 12 MP TrueDepth front camera\n",
      "\n",
      "Xiaomi Mi 11 Youth 5G Premium Edition Dual SIM TD-LTE CN 256GB M2101K9C is a Chinese variant of Mi11 Lite 5G smartphone with 256 GB UFS 2.2 ROM, 8 GiB LP-DDR4X RAM. Xiaomi Mi 11 Youth 5G Premium Edition Dual SIM TD-LTE CN 128GB M2101K9C is a Chinese variant of Mi11 Lite 5G smartphone with 128 GB UFS 2.2 ROM, 8 GiB LP-DDR4X RAM. Xiaomi Mi 11 Pro 5G Premium Edition Dual SIM TD-LTE CN 256GB M2102K1AC is a Chinese variant of Mi11 Pro 5G smartphone with 256 GB UFS 2.2 ROM, 8 GiB LP-DDR4X RAM.\n",
      "\n",
      "The Samsung SM-G9960 Galaxy S21+ 5G Dual SIM TD-LTE CN HK 256GB is a powerful cellphone with a 12.2 MP camera, Samsung ISOCELL Plus S5K2LD camera module, and an adaptive display with support for 10 Hz to 120 Hz at Quad HD+ quality. It also has dual nano-SIM slots and 128 GB of storage. The Samsung SM-G9960 Galaxy S21+ 5G Dual SIM TD-LTE CN HK 128GB is a powerful cellphone with a 12.2 MP camera, Samsung ISOCELL Plus S5K2LD camera module, and an adaptive display with support for 10 Hz to 120 Hz at Quad HD+ quality. It also has dual nano-SIM slots and 128 GB of storage. The Samsung SM-G9980 Galaxy S21 Ultra 5G Dual SIM TD-LTE C\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "................................................\n",
      "Back to the original question >>>>>> \n",
      "------------------------------------------------\n",
      "Question:\n",
      "  How do the camera capabilities of the Apple iPhone 12,Samsung Galaxy S21, and Xiaomi Mi 11 compare?\n",
      "\n",
      "\n",
      "Answer:\n",
      " The camera capabilities of the Apple iPhone 12, Samsung Galaxy S21, and Xiaomi Mi 11 are similar. The iPhone 12 has a 12 MP wide-angle rear camera and a 12 MP TrueDepth front camera. The Galaxy S21 has a 12 MP wide-angle rear camera and a 12 MP TrueDepth front camera. The Mi 11 has a 12 MP wide-angle rear camera and a 12 MP TrueDepth front camera.\n"
     ]
    }
   ],
   "source": [
    "#Alpaca-base model fusion pipelines\n",
    "\n",
    "question = \"How do the camera capabilities of the Apple iPhone 12,\\\n",
    "Samsung Galaxy S21, and Xiaomi Mi 11 compare?\"\n",
    "\n",
    "key_names = name_query_mix_models_inference(question, name_list, print_process=True)\n",
    "\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Querying local DataBase ......\")\n",
    "\n",
    "context_text = \"\"\n",
    "for n in key_names:\n",
    "    keys_texts = query_key_text_list(n)\n",
    "    relevant_texts = []\n",
    "    \n",
    "    print(\"Model Name Family: \", n)\n",
    "    \n",
    "    # too many texts, crashed the alpaca model, added a simple filter\n",
    "    topk = 3\n",
    "    keys_list = []\n",
    "    texts_list = []\n",
    "    for key, text in keys_texts:\n",
    "        keys_list.append(key)\n",
    "        texts_list.append(text)\n",
    "    cls_res = efficient_bart_cls_inference(question, keys_list)\n",
    "    keys_texts_ranked = []\n",
    "    ranked_keys = cls_res[\"labels\"][0 : topk]\n",
    "    for i in range(len(keys_list)):\n",
    "        if keys_list[i] in ranked_keys:\n",
    "            keys_texts_ranked.append([keys_list[i], texts_list[i]])\n",
    "    \n",
    "    \n",
    "    for ln, text in keys_texts_ranked:\n",
    "        relevant_text = \"Model full name is '\" + ln + \"':\\n\"\n",
    "        relevant_text += relevant_table_text(question, text, topk=3)\n",
    "        relevant_text += \"\\n\"\n",
    "        #print(relevant_text)\n",
    "        relevant_texts.append(relevant_text)\n",
    "    sum_rele_text = ' '.join(relevant_texts)\n",
    "    #print(sum_rele_text)\n",
    "    \n",
    "    # invoke Alpaca to summarize\n",
    "    instruction = '''Summarize the input passage which contains info about\\\n",
    "different specific models of a cellphone family\n",
    "'''\n",
    "    input_text = sum_rele_text\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output = alpaca_inference(input_text, instruction)\n",
    "    \n",
    "    output = output.split('###')[0].strip()\n",
    "    output = output.strip()\n",
    "    context_text += output + \"\\n\\n\" \n",
    "    \n",
    "        \n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "print(context_text)\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"................................................\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final inference to answer the question\n",
    "instruction = \"Answer the input question.\\n\\n\\\n",
    "You are given the following context information extracted from local database:\\n\\n\"\n",
    "instruction += context_text\n",
    "input_text = question\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "output = output.split('###')[0].strip()\n",
    "output = output.strip()\n",
    "\n",
    "print(\"Back to the original question >>>>>> \")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Question:\\n \", question)\n",
    "print(\"\\n\\nAnswer:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127dd347-1570-440b-b123-7fd27f9ec384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5ea7c-b20b-4329-8ee0-aa4779a4b7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fcd368-2c4b-4581-a392-c6a8e01272ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32046f5-bdc5-4c87-875d-09d31cdc6016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract all phone model names from the input sentence. Append and prepend '%%%' symbols to each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " What is the maximum refresh rate of the iPhone 12 Pro Max display and how does it compare to the Samsung Galaxy Note20 Ultra?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%iPhone 12 Pro Max%% %%Samsung Galaxy Note20 Ultra%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['iPhone 12 Pro Max', 'Samsung Galaxy Note20 Ultra']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Zero-shot BART classifier extract name keys\n",
      "\n",
      "Extracted Model Name:  iPhone 12 Pro Max\n",
      "Extracted Model Name:  Samsung Galaxy Note 20 Ultra\n",
      "------------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Querying local DataBase ......\n",
      "Model Name Family:  iPhone 12 Pro Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [00:01<00:00, 90.45it/s]\n",
      "100%|██████████| 162/162 [00:01<00:00, 94.63it/s]\n",
      "100%|██████████| 162/162 [00:01<00:00, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name Family:  Samsung Galaxy Note 20 Ultra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [00:01<00:00, 89.10it/s]\n",
      "100%|██████████| 167/167 [00:01<00:00, 94.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "The iPhone 12 Pro Max 5G A2412 Dual SIM TD-LTE CN 512GB / A2413 has a 60Hz display refresh rate, a 120Hz touchscreen sampling rate, and a 60Hz display refresh rate. The iPhone 12 Pro Max 5G A2412 Dual SIM TD-LTE CN 256GB / A2413 has a 60Hz display refresh rate, a 120Hz touchscreen sampling rate, and a 60Hz display refresh rate. The iPhone 12 Pro Max 5G A2412 Dual SIM TD-LTE CN 128GB / A2413 has a 60Hz display refresh rate, a 120Hz touchscreen sampling rate, and a 60Hz display refresh rate.\n",
      "\n",
      "The Samsung SM-N9860 Galaxy Note 20 Ultra 5G Dual SIM TD-LTE CN 512GB and the Samsung SM-N9860 Galaxy Note 20 Ultra 5G Dual SIM TD-LTE CN 256GB are two variants of the same phone, the Galaxy Note 20 Ultra 5G. Both variants have a 6.7-inch Super AMOLED display with a 120Hz refresh rate, a Snapdragon 865 chipset, and 512GB or 256GB of storage. The SM-N9860 Galaxy Note 20 Ultra 5G Dual SIM TD-LTE CN 512GB has a 512GB of storage, while the SM-N9860 Galaxy Note 20 Ultra 5G Dual SIM TD-LTE CN 256GB has a 256GB of storage. Both variants have a triple camera setup on the back, with a 48\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "................................................\n",
      "Back to the original question >>>>>> \n",
      "------------------------------------------------\n",
      "Question:\n",
      "  What is the maximum refresh rate of the iPhone 12 Pro Max display and how does it compare to the Samsung Galaxy Note20 Ultra?\n",
      "\n",
      "\n",
      "Answer:\n",
      " The iPhone 12 Pro Max display has a maximum refresh rate of 60Hz. The Samsung Galaxy Note20 Ultra display has a maximum refresh rate of 120Hz.\n"
     ]
    }
   ],
   "source": [
    "question = '''\\\n",
    "What is the maximum refresh rate of the iPhone 12 Pro \\\n",
    "Max display and how does it compare to the Samsung Galaxy Note20 Ultra?'''\n",
    "key_names = name_query_mix_models_inference(question, name_list, print_process=True)\n",
    "\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Querying local DataBase ......\")\n",
    "\n",
    "context_text = \"\"\n",
    "for n in key_names:\n",
    "    keys_texts = query_key_text_list(n)\n",
    "    relevant_texts = []\n",
    "    \n",
    "    print(\"Model Name Family: \", n)\n",
    "    \n",
    "    # too many texts, crashed the alpaca model, added a simple filter\n",
    "    topk = 3\n",
    "    keys_list = []\n",
    "    texts_list = []\n",
    "    for key, text in keys_texts:\n",
    "        keys_list.append(key)\n",
    "        texts_list.append(text)\n",
    "    cls_res = efficient_bart_cls_inference(question, keys_list)\n",
    "    keys_texts_ranked = []\n",
    "    ranked_keys = cls_res[\"labels\"][0 : topk]\n",
    "    for i in range(len(keys_list)):\n",
    "        if keys_list[i] in ranked_keys:\n",
    "            keys_texts_ranked.append([keys_list[i], texts_list[i]])\n",
    "    \n",
    "    \n",
    "    for ln, text in keys_texts_ranked:\n",
    "        relevant_text = \"Model full name is '\" + ln + \"':\\n\"\n",
    "        relevant_text += relevant_table_text(question, text, topk=3)\n",
    "        relevant_text += \"\\n\"\n",
    "        #print(relevant_text)\n",
    "        relevant_texts.append(relevant_text)\n",
    "    sum_rele_text = ' '.join(relevant_texts)\n",
    "    #print(sum_rele_text)\n",
    "    \n",
    "    # invoke Alpaca to summarize\n",
    "    instruction = '''Summarize the input passage which contains info about\\\n",
    "different specific models of a cellphone family\n",
    "'''\n",
    "    input_text = sum_rele_text\n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output = alpaca_inference(input_text, instruction)\n",
    "    \n",
    "    output = output.split('###')[0].strip()\n",
    "    output = output.strip()\n",
    "    context_text += output + \"\\n\\n\" \n",
    "    \n",
    "        \n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "print(context_text)\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"................................................\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Final inference to answer the question\n",
    "instruction = \"Answer the input question.\\n\\n\\\n",
    "You are given the following context information extracted from local database:\\n\\n\"\n",
    "instruction += context_text\n",
    "input_text = question\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "output = output.split('###')[0].strip()\n",
    "output = output.strip()\n",
    "\n",
    "print(\"Back to the original question >>>>>> \")\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"Question:\\n \", question)\n",
    "print(\"\\n\\nAnswer:\\n\", output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456674e-841d-4daf-af4d-0380f99fead5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cbf24b-1e2c-405b-bc8d-503927cc7ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36739f6-1fd0-4b6f-926b-87d43bf3a1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
