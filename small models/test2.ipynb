{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46b561c-6083-43dc-aa1d-5cd16bda0292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 00:07:03.484029: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-18 00:07:05.568740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-04-18 00:07:08.623760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 00:07:08.682787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-18 00:07:08.683340: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# reconstruct related variables for inferencing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "import re\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "QA = pd.read_csv('QA.csv')\n",
    "qListTemp = []\n",
    "aListTemp = []\n",
    "for q in QA['Q']:\n",
    "    qListTemp.append(q)\n",
    "for a in QA['A']:\n",
    "    aListTemp.append(a)\n",
    "questionTweets = qListTemp\n",
    "answerTweets = aListTemp\n",
    "pairs = list(zip(questionTweets,answerTweets))\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "for tweet in pairs:\n",
    "    input_doc, target_doc = tweet[0], tweet[1]\n",
    "    input_docs.append(input_doc)\n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    target_doc = '<START> ' + target_doc + ' <END>' \n",
    "    target_docs.append(target_doc)\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "    for token in target_doc.split():\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)\n",
    "\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "target_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items())\n",
    "\n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "max_decoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc)) for target_doc in target_docs])\n",
    "\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1. \n",
    "\n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1. \n",
    "        if timestep > 0: \n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e89926c-b888-4b52-8e27-81cd026c9d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 00:07:09.336242: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-18 00:07:09.338842: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-18 00:07:09.340468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-18 00:07:09.649787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-18 00:07:09.652154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-18 00:07:09.653815: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None, 541)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None, 1121)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        817152      ['input_1[0][0]']                \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  1411072     ['input_2[0][0]',                \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1121)   288097      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,516,321\n",
      "Trainable params: 2,516,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load the trained weights\n",
    "training_model = load_model('training_model2.h5')\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d4b73b-3179-49d8-96c2-09f4e99de6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 00:07:13.574195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-18 00:07:13.576921: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-18 00:07:13.578817: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "# use encorder model to get the final hidden state and cell state, which in turn become the initial\n",
    "# hidden state and cell state for decorder\n",
    "encoder_inputs = training_model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "latent_dim = 256\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "decoder_lstm = training_model.layers[3]\n",
    "decoder_inputs = training_model.input[1]\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "decoder_dense = training_model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "#During the decoding process, the first word is predicted based on decoder's hidden state and cell state and\n",
    "# <START> token, and then the second word is predict based on the decoder's previous hidden state and cell state\n",
    "# and the first word. The process is continued until <END> token is predicted.\n",
    "def decode_response(test_input):\n",
    "    states_value = encoder_model.predict(test_input,verbose=0)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "    decoded_sentence = ''\n",
    "    stop_condition = False\n",
    "    while not stop_condition:\n",
    "        output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value,verbose=0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == '<END>':\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "        states_value = [hidden_state, cell_state]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa947328-3e74-4f57-a980-d565658ca618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a chat bot class for chatting\n",
    "class ChatBot:\n",
    "    negative_responses = (\"no\", \"nope\", \"nah\", \"naw\", \"not a chance\", \"sorry\")\n",
    "    exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
    "    \n",
    "\n",
    "    def chat(self):\n",
    "        print(\"Chatbot: Hello, what can I do for you?\")\n",
    "        reply = input()\n",
    "        while not self.make_exit(reply):\n",
    "            reply = input(\"Chatbot:\"+self.generate_response(reply)+\"\\n\")\n",
    "    \n",
    " \n",
    "    def string_to_matrix(self, user_input):\n",
    "        # convert user input question to encoder data\n",
    "        tokens = re.findall(r\"[\\w']+|[^\\s\\w]\", user_input)\n",
    "        user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "        for timestep, token in enumerate(tokens):\n",
    "            if token in input_features_dict:\n",
    "                user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
    "        return user_input_matrix\n",
    "  \n",
    "    def generate_response(self, user_input):\n",
    "        input_matrix = self.string_to_matrix(user_input)\n",
    "        chatbot_response = decode_response(input_matrix)\n",
    "        chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
    "        chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
    "        return chatbot_response\n",
    "\n",
    "    def make_exit(self, reply):\n",
    "        for exit_command in self.exit_commands:\n",
    "            if exit_command in reply:\n",
    "                print(\"Chatbot: Ok, have a great day!\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3fafa8-1b6e-4a04-a6ef-49441ab527c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Hello, what can I do for you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " I can't remember my Apple ID password. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 00:07:59.562722: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-18 00:07:59.565337: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-18 00:07:59.566956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-04-18 00:08:00.068859: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-04-18 00:08:00.071348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-04-18 00:08:00.073076: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Chatbot: No problem . Let's try resetting your password . Go to iforgot . apple . com and enter your Apple ID . Follow the steps to verify your identity , and then you'll be able to reset your password . If you're still having issues , caution doing caution doing caution . \n",
      " My iPad won't turn on. \n",
      "Chatbot: Let's try a force restart . Hold down the Home button and the Power button at the same time for at least 10 seconds , until you see the Apple logo . If that doesn't work , try charging your iPad for at least caution appears appears estimate estimate estimate If it does caution it repairs repairs . To To To To To To To To To To To To . \n",
      " Hi, I’m having trouble with my MacBook. It won’t turn on.\n",
      "Chatbot: Sure , let ’ s start by resetting the System Management Controller ( SMC ) . Have you tried that yet \n",
      "  Hi, I’m having trouble with my AirPods. \n",
      "Chatbot: Sure , let ’ s start by resetting your AirPods . Have you tried that yet . \n",
      " airpods\n",
      "Chatbot: Yes , there are several things you can do to optimize your MacBook's performance . We can go through some troubleshooting steps to see if we can improve its speed Water Your . \n",
      " : Hi, I’m having trouble with my iPad\n",
      "Chatbot: Sure , let ’ s start by restarting your iPad . Have you tried that yet . \n",
      " iPad's battery drain quickly\n",
      "Chatbot: You can try a basic off your lost or suspend your account and report the loss to the police . You locked \" Payment & Shipping the brand and connections or performing a factory reset , which will erase all data . \n",
      " iPad's battery drains quickly\n",
      "Chatbot: You can try closing any unused apps , clearing your phone's cache , and disabling any unnecessary background processes . If the problem persists , you can try performing a factory reset , but make sure to backup your data first . \n",
      " iPad's battery drain quickly\n",
      "Chatbot: You can try a basic off your lost or suspend your account and report the loss to the police . You locked \" Payment & Shipping the brand and connections or performing a factory reset , which will erase all data . \n",
      " I accidentally locked myself out of my phone\n",
      "Chatbot: If you have a backup PIN or password , you can try using that to unlock your phone . If not , you can try using the \" Find My Device \" feature to remotely unlock your phone or perform a factory reset . However , this will erase all your data , so make sure to backup your phone first . \n",
      " Why is my phone running slowly\n",
      "Chatbot: Your phone may be running slowly due to a lack of storage space , too many running apps , or outdated software . Try clearing some space , closing background apps , and updating your software . \n",
      " How do I activate my new SIM card? \n",
      "Chatbot: You can activate your new SIM card by calling our customer service hotline or visiting one of our retail stores . \n",
      " : My phone is not charging properly. \n",
      "Chatbot: Have you tried using a different charging cable or adapter ? It could be an issue with the PRAM and deliver presentations . \n",
      " My phone's battery drains quickly.\n",
      "Chatbot: You can try reducing your phone's screen brightness and turning off any unnecessary features like location services or Bluetooth . You can also try replacing the battery or using a battery - saving app to extend your phone's battery life . \n",
      " My phone's speaker is not working\n",
      "Chatbot: Yes , there are several things you can do to optimize your MacBook's performance . We can go through some troubleshooting steps to see if we can improve its speed . \n",
      " bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot: Ok, have a great day!\n"
     ]
    }
   ],
   "source": [
    "chatbot = ChatBot()\n",
    "chatbot.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddf2754-dd84-49ec-bb13-2a3fe676874d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
